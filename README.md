# Multimodal-IAD

Multimodal System Providing Textual Explanations for Image Anomaly Detection


## Getting Started

### Prerequisites

- Python 3.10 or higher
- uv package manager (pip is also possible)

### Installation
```bash
git clone https://github.com/open-edge-platform/multimodal-iad.git
cd multimodal-iad
```

Setting the environment variable `GIT_LFS_SKIP_SMUDGE=1` is necessary because of an anomalib install bug.
Install application and dependencies:
```bash
GIT_LFS_SKIP_SMUDGE=1 uv sync
```

### Usage
Set the environment variable `GEMINI_API_KEY` to your Google Gemini API key (i.e. via .env file).

Run the GUI application:
```bash
uv run multimodal-iad
```

## Development
Note that currently anomalib f1_adaptive_threshold is not working as expected (Index out of bounds error).
Locally, there is a quickfix in the code, but the underlying issue should be fixed in anomalib.
Maybe, fork it later.



## Project Overview

This project aims to develop an interface for applying Image Anomaly Detection (IAD) to multimodal input and offering multimodal explanations as part of the output. 
The system is primarily intended for the deployment and analysis of IAD-based quality inspection systems, but could also be used for debugging strengths and weaknesses of IAD algorithms.

This system offers:
- A minimal graphical user interface (GUI) that displays the decision (normal or abnormal)
- Image-level and pixel-level predictions as visual explanation determined by a state-of-the-art deep learning-based AD method
- Textual explanations generated by a multimodal LLM (especially useful for unpictureable anomalies)
- Audio output for signaling abnormal predictions

## Project Architecture

The project consists of two main components:

### 1. Multimodal IAD
- Train and apply an unsupervised IAD algorithm on normal 2D and multimodal input data (MVTecAD-3D, MVTec AD 2) using anomalib 2.0
- Process data from different kinds of sensors (RGB and IR cameras for RGB and depth data)
- Use pre-recorded data for development and testing

### 2. Multimodal Interface
- GUI for selecting input sources
- Display multimodal output:
  - Predicted anomaly label
  - Anomaly score (confidence)
  - Anomaly location (anomaly map) as visual explanation
  - Abnormality reason as textual explanation
- Audio output for signaling abnormal predictions during inference

## Features

- **Multimodal Input Processing**: Handle RGB and depth data from different sensors
- **Advanced Anomaly Detection**: Utilize anomalib 2.0 for state-of-the-art anomaly detection and experiments
- **Visual Explanations**: Display heatmaps highlighting anomalous areas
- **Textual Explanations**: Generate human-readable explanations using multimodal LLMs
- **Audio Feedback**: Provide audio alerts and explanations for hands-free operation
- **User-friendly Interface**: Built with PyQt6 for a responsive and intuitive GUI

## Task List

### Phase 1: Setup and Infrastructure
- [x] Initialize project structure
- [x] Set up basic dependencies
- [x] Add PyQt6 to dependencies
- [ ] Create comprehensive project documentation

### Phase 2: Core IAD Implementation
- [ ] Implement data loading and preprocessing for multimodal inputs
- [ ] Integrate anomalib 2.0 for anomaly detection
- [ ] Develop training pipeline for unsupervised IAD
- [ ] Implement inference pipeline for anomaly detection
- [ ] Create visualization module for anomaly heatmaps

### Phase 3: Multimodal LLM Integration
- [ ] Research and select appropriate multimodal LLM
- [ ] Develop prompting strategy for anomaly explanation
- [ ] Implement LLM integration for textual explanations
- [ ] Create evaluation metrics for explanation quality

### Phase 4: GUI Development
- [ ] Design basic PyQt6 interface layout
- [ ] Implement input source selection
- [ ] Create visualization panels for multimodal output
- [ ] Develop settings and configuration interface
- [ ] Add audio output functionality

### Phase 5: Testing and Refinement
- [ ] Evaluate explanation quality and usefulness
- [ ] Perform usability testing of the GUI
- [ ] Optimize performance for real-time operation
- [ ] Document system limitations and future improvements

## Installation

### Prerequisites
- Python 3.10 or higher
- pip or uv package manager

### Steps
1. Clone the repository:
   ```
   git clone https://github.com/yourusername/multimodal-iad.git
   cd multimodal-iad
   ```

2. Install dependencies:
   ```
   pip install -e . # for pip
   uv pip install -e . # for uv
   ```

3. For development dependencies:
   ```
   pip install -e ".[dev]" # for pip
   uv pip install -e ".[dev]" # for uv
   ```

## Usage
Basic usage will be:

```python
# TODO
```

## Dependencies

- **anomalib** (≥2.0.0): Advanced anomaly detection library
- **PyQt6**: GUI framework
- **Development tools**:
  - ruff (≥0.12.0): Python linter

## Major Contributions

- Exploring capabilities of Multimodal LLMs for providing IAD explanations
- Building a multimodal interface for IAD systems
- Enhancing usability of IAD systems for industrial applications
